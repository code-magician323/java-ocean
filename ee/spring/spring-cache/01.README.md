## 使用场景: `缓存只保证最终一致性`

1. 即时性, 数据一致性要求不高: _物流信息_, _商品分类_
2. 访问量大, 但是更新频率不高的数据`[读多写少]`: _商品信息_
3. 遇到实时性一致性要求超高的, 应该直接查询数据库

## 缓存分类

1. 本地缓存

   - 比如存在 Map 中, 只适用于单体应用
   - 分布式下存在数据不一致问题

2. 分布式缓存

### 本地缓存锁

![avatar](/static/image/db/redis-standalone.png)

1. 确保以下 3 个动作是原子的, 二期是在锁住的方法内
   - query from redis cache
   - query database
   - put result to redis cache.-

### 分布式缓存锁

![avatar](/static/image/db/redis-distribute.png)

1. core: 在指定地方占一个位置, 占上位置就可以执行逻辑, 否则等待
2. 加锁[原子操作]: `SET K V NX EX`
3. 释放锁[原子操作]: `if redis.call('get',KEYS[1]) == ARGV[1] then return redis.call('del',KEYS[1]) else return 0 end` 返回值时 Long
4. 只能删除自己的锁, 业务逻辑时间长导致的 redis key 过期而引起的删除别人持有的锁: 可以适当的设置 redis key 过期时间长一点
5. processor

   ![avatar](/static/image/db/redis-distribute-v1.png)
   ![avatar](/static/image/db/redis-distribute-v2.png)
   ![avatar](/static/image/db/redis-distribute-v3.png)
   ![avatar](/static/image/db/redis-distribute-v4.png)

6. redission 也还是会出现主从同步锁丢失的问题:

   - Zookeeper 可以解决这个问题(CP)
   - 也可以使用 RedLock 向多个 redis 内加锁, 半数成功才认为加锁成功

7. 继续优化
   - 分段锁: 将库存分为多个阶段, 对每个阶段进行加锁减库存操作
   - 读写锁

### 分布式缓存框架 Redisson

1. Redisson 是一个在 Redis 的基础上实现的 Java 驻内存数据网格[In-Memory Data Grid]
2. 它不仅提供了一系列的分布式的 Java 常用对象, 还提供了许多分布式服务
   - BitSet
   - Set
   - Multimap
   - SortedSet
   - Map
   - List
   - Queue
   - BlockingQueue
   - Deque
   - BlockingDeque
   - Semaphore
   - Lock
   - AtomicLong
   - CountDownLatch
   - Publish / Subscribe
   - Bloom filter
   - Remote service
   - Spring cache
   - Executor service
   - Live Object service
   - Scheduler service
3. Redisson 提供了使用 Redis 的最简单和最便捷的方法
4. Redisson 的宗旨是促进使用者对 Redis 的关注分离[Separation of Concern], 从而让使用者能够将精力更集中地放在处理业务逻辑上
5. Redisson 实现类 JUC 的锁
6. 锁续期: 看门狗
7. 还是会出现主从同步锁丢失的问题

#### lock

1. redisson 获取锁时时阻塞等待, 而不是自旋
   - lock.lock(long leaseTime, TimeUnit unit): 不会自动续期, 过期之后就会被删除
2. redisson 获取分布式锁, 名字相同即为一把锁
3. redisson 不会出现死锁: 锁的过期时间默认为 30s
4. redisson 锁的自动续期: 看门狗
   - lock(-1, TimeUnit unit): 获取锁, 设置默认的时间哪位 30s, 并在占锁成功之后设置一个定时器对锁进行续期[30s/3=10s]
5. 最佳实战:
   - `lock(20, TimeUtil.SECONDS): 省下了续期操作, 手动解锁`

#### tryLock

1. 最大等待时间, 否则就放弃
   - boolean b = lock.tryLock(100, 10, TimeUnit.SECONDS): `最大等待100s, 最长持有时间 10s就释放锁`

#### FairLock: 公平锁

1. 有顺序的获取锁

   - RLock lock = redisson.getFairLock("anyLock")

#### 读写所: `经常读, 很少写`

1. 允许多个读锁和一个写锁处于加锁状态

   ```java
   RReadWriteLock rwlock = redisson.getReadWriteLock("rwlock");
   rwlock.readLock().lock();
   rwlock.writeLock().lock();
   ```

2. 读数据使用读锁, 写数据使用写锁

3. 读写锁也会自动续期, 但是可以读到最新的数据[修改期间会阻塞所有操作]
   - 写 + 读: 等待写锁释放
   - 写 + 写: 阻塞写
   - 读 + 写: 等待写锁释放
   - 读 + 读: 无锁, 只会记录所有的读锁, 都能加锁成功

#### 闭锁

1. demo: 等 5 个班都锁门, 才可以锁学校大门
2. getCountDownLatch Key 过期时间 -1
3. latch count 为 0, 最小值为 0
4. getCountDownLatch 会阻塞, 直到 count=0 时才执行

#### 信号量: 限流

1. demo: 停车场, 限流
2. park 过期时间为 -1
3. 当没有车位时, 停车动作会被阻塞, 直到有车离开[空出车位]
4. 车离开没有限制
5. 限流:

   - 信号量为 1000, 当线程来时取一个, 执行结束则返还, 1000 个信号量被取完则线程需要等待
   - code

     ```java
     boolean acquire = park.tryAcquire();
     if(acquire) {
        // buz logic
     } else {
        return "当前流量过大";
     }
     ```

## 缓存数据的一致性问题

1. 双写模式: `第二个线程写缓存先执行了导致`的不一致, 而且缓存有时不是淡出的数据[经过相关的逻辑结果、频繁呗修改但是没有使用(更新缓存是没有意义的)]

   ![avatar](/static/image/db/redis-data-consistency.png)

2. 失效模式: 先写数据库, 之后再删除缓存

   - `第三个执行查询写入 redis 快于第二个, 会导致多查数据库`
   - `1 删除结束, 3 进行数据库查询, 2 更新了数据库并删除了缓存, 3 开始写如redis, 此时的数据就不会死最新的[2操作后的数据时最新的]`

   ![avatar](/static/image/db/redis-data-consistency-v2.png)

   - solution1: 可以使用读写锁, 2 在写时, 3 读会被阻塞
   - solution2: 使用 BlockingQueue 进行排序

3. 失效模式: 先删除缓存, 之后再写数据库

   - issue: 删除换粗失败则数据就不对了 & 删除缓存之后写入数据库之前有查询则缓存旧的数据
   - solution3: 延时双删[先删除缓存, 在写数据库, 之后休眠一会才删除缓存]

4. 解决方案

   - 如果时用户维度的数据(订单数据, 用户数据), 并发几率小, `缓存+过期时间+失效模式` 就可以了
   - 如果时菜单, 商品介绍等数据[可以长时间数据不一致]: `canal-binlog`
   - 要求一致性高的可以考虑加锁: `读写锁`
   - 遇到实时性一致性要求超高的, 应该直接查询数据库

## Spring Cache

1. 相关概念

   - CacheManager
   - Cache
   - store: K-V

2. Spring-Cache 的不足之处

   - 读模式
     1. 缓存穿透: 查询一个 null 数据。解决方案: 缓存空数据, 可通过 spring.cache.redis.cache-null-values=true
     2. 缓存击穿: 大量并发进来同时查询一个正好过期的数据。解决方案: 加锁 ? 默认是无加锁的;
     3. 使用 sync = true 来解决击穿问题
     4. 缓存雪崩: 大量的 key 同时过期。解决: 加随机时间。加上过期时间
   - 写模式: 缓存与数据库一致
     1. 读写加锁
     2. 引入 Canal,感知到 MySQL 的更新去更新 Redis
     3. 读多写多, 直接去数据库查询就行
   - 总结:

     1. 常规数据(读多写少, 即时性, 一致性要求不高的数据, 完全可以使用 Spring-Cache):
     2. 写模式(只要缓存的数据有过期时间就足够了)
     3. 特殊数据: 特殊设计

## issue list

1. OutOfDirectMemoryError:

   - root cause: lettuce's bug, 内存没有得到及时的释放, netty 如果不设置堆外内存则会使用 `-Xmx100m`

   ```java
   // io.netty.util.internal.PlatformDependent
   logger.debug("-Dio.netty.maxDirectMemory: {} bytes", maxDirectMemory);
   DIRECT_MEMORY_LIMIT = maxDirectMemory >= 1 ? maxDirectMemory : MAX_DIRECT_MEMORY;

   private static void incrementMemoryCounter(int capacity) {
       if (DIRECT_MEMORY_COUNTER != null) {
           long newUsedMemory = DIRECT_MEMORY_COUNTER.addAndGet(capacity);
           if (newUsedMemory > DIRECT_MEMORY_LIMIT) {
               DIRECT_MEMORY_COUNTER.addAndGet(-capacity);
               throw new OutOfDirectMemoryError("failed to allocate " + capacity
                       + " byte(s) of direct memory (used: " + (newUsedMemory - capacity)
                       + ", max: " + DIRECT_MEMORY_LIMIT + ')');
           }
       }
   }
   ```

   - solution:
     1. `-Dio.netty.maxDirectMemory`: 长时间运行还是有问题的, 本质还是内存没有得到及时的释放
     2. 使用 jedis,
     3. 升级 lettuce: `5.2.2.RELEASE`
